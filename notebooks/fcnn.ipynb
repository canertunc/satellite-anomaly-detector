{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy matplotlib seaborn scikit-learn torch joblib"
      ],
      "metadata": {
        "id": "L6H9revKZYm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data analysis and Prep."
      ],
      "metadata": {
        "id": "cWsQ1_DCqu1t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPQn1c7sZUBK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('dataset.csv')"
      ],
      "metadata": {
        "id": "ZT6qppNiZYYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(48)"
      ],
      "metadata": {
        "id": "dGsLkdN4slLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "JuNsXZgIc9Gz",
        "outputId": "5cc0450b-a3e5-4b5b-87f4-7581b5317cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   segment  anomaly  train   channel  sampling  duration  len          mean  \\\n",
              "0        1        1      1  CADC0872         1       279  280  8.533143e-07   \n",
              "1        2        1      1  CADC0872         1       476  477 -3.639396e-06   \n",
              "2        3        1      1  CADC0872         1       594  595  1.170788e-05   \n",
              "3        4        1      1  CADC0872         1       271  272  8.486808e-07   \n",
              "4        5        0      0  CADC0872         1       255  257  1.058485e-05   \n",
              "\n",
              "            var       std  ...  smooth10_n_peaks  smooth20_n_peaks  \\\n",
              "0  3.494283e-10  0.000019  ...                 3                 2   \n",
              "1  6.476485e-10  0.000025  ...                 1                 1   \n",
              "2  5.592877e-10  0.000024  ...                 2                 2   \n",
              "3  5.466024e-10  0.000023  ...                 2                 2   \n",
              "4  5.279023e-10  0.000023  ...                 1                 1   \n",
              "\n",
              "   diff_peaks  diff2_peaks      diff_var     diff2_var  gaps_squared  \\\n",
              "0           4            6  1.271176e-10  2.960666e-10           309   \n",
              "1           5            8  1.489383e-12  3.004752e-12           644   \n",
              "2           2            3  4.112280e-12  1.029918e-11           772   \n",
              "3           3            6  2.475760e-11  6.240985e-11           339   \n",
              "4          78           87  5.547101e-13  7.035422e-13           357   \n",
              "\n",
              "   len_weighted  var_div_duration   var_div_len  \n",
              "0           280      1.252431e-12  1.247958e-12  \n",
              "1           477      1.360606e-12  1.357754e-12  \n",
              "2           595      9.415618e-13  9.399794e-13  \n",
              "3           272      2.016983e-12  2.009568e-12  \n",
              "4           257      2.070205e-12  2.054094e-12  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-069c4f11-d225-4ea6-b30b-ce48f2f7c80f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>segment</th>\n",
              "      <th>anomaly</th>\n",
              "      <th>train</th>\n",
              "      <th>channel</th>\n",
              "      <th>sampling</th>\n",
              "      <th>duration</th>\n",
              "      <th>len</th>\n",
              "      <th>mean</th>\n",
              "      <th>var</th>\n",
              "      <th>std</th>\n",
              "      <th>...</th>\n",
              "      <th>smooth10_n_peaks</th>\n",
              "      <th>smooth20_n_peaks</th>\n",
              "      <th>diff_peaks</th>\n",
              "      <th>diff2_peaks</th>\n",
              "      <th>diff_var</th>\n",
              "      <th>diff2_var</th>\n",
              "      <th>gaps_squared</th>\n",
              "      <th>len_weighted</th>\n",
              "      <th>var_div_duration</th>\n",
              "      <th>var_div_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>CADC0872</td>\n",
              "      <td>1</td>\n",
              "      <td>279</td>\n",
              "      <td>280</td>\n",
              "      <td>8.533143e-07</td>\n",
              "      <td>3.494283e-10</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1.271176e-10</td>\n",
              "      <td>2.960666e-10</td>\n",
              "      <td>309</td>\n",
              "      <td>280</td>\n",
              "      <td>1.252431e-12</td>\n",
              "      <td>1.247958e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>CADC0872</td>\n",
              "      <td>1</td>\n",
              "      <td>476</td>\n",
              "      <td>477</td>\n",
              "      <td>-3.639396e-06</td>\n",
              "      <td>6.476485e-10</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1.489383e-12</td>\n",
              "      <td>3.004752e-12</td>\n",
              "      <td>644</td>\n",
              "      <td>477</td>\n",
              "      <td>1.360606e-12</td>\n",
              "      <td>1.357754e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>CADC0872</td>\n",
              "      <td>1</td>\n",
              "      <td>594</td>\n",
              "      <td>595</td>\n",
              "      <td>1.170788e-05</td>\n",
              "      <td>5.592877e-10</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4.112280e-12</td>\n",
              "      <td>1.029918e-11</td>\n",
              "      <td>772</td>\n",
              "      <td>595</td>\n",
              "      <td>9.415618e-13</td>\n",
              "      <td>9.399794e-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>CADC0872</td>\n",
              "      <td>1</td>\n",
              "      <td>271</td>\n",
              "      <td>272</td>\n",
              "      <td>8.486808e-07</td>\n",
              "      <td>5.466024e-10</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>2.475760e-11</td>\n",
              "      <td>6.240985e-11</td>\n",
              "      <td>339</td>\n",
              "      <td>272</td>\n",
              "      <td>2.016983e-12</td>\n",
              "      <td>2.009568e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>CADC0872</td>\n",
              "      <td>1</td>\n",
              "      <td>255</td>\n",
              "      <td>257</td>\n",
              "      <td>1.058485e-05</td>\n",
              "      <td>5.279023e-10</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>78</td>\n",
              "      <td>87</td>\n",
              "      <td>5.547101e-13</td>\n",
              "      <td>7.035422e-13</td>\n",
              "      <td>357</td>\n",
              "      <td>257</td>\n",
              "      <td>2.070205e-12</td>\n",
              "      <td>2.054094e-12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-069c4f11-d225-4ea6-b30b-ce48f2f7c80f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-069c4f11-d225-4ea6-b30b-ce48f2f7c80f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-069c4f11-d225-4ea6-b30b-ce48f2f7c80f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-43813dbe-795c-4076-bf37-8fa7a6ef6ee7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43813dbe-795c-4076-bf37-8fa7a6ef6ee7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-43813dbe-795c-4076-bf37-8fa7a6ef6ee7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEymVDuEZYa-",
        "outputId": "eae2cb82-87f9-4796-b93a-2548bfcd4d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2123 entries, 0 to 2122\n",
            "Data columns (total 23 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   segment           2123 non-null   int64  \n",
            " 1   anomaly           2123 non-null   int64  \n",
            " 2   train             2123 non-null   int64  \n",
            " 3   channel           2123 non-null   object \n",
            " 4   sampling          2123 non-null   int64  \n",
            " 5   duration          2123 non-null   int64  \n",
            " 6   len               2123 non-null   int64  \n",
            " 7   mean              2123 non-null   float64\n",
            " 8   var               2123 non-null   float64\n",
            " 9   std               2123 non-null   float64\n",
            " 10  kurtosis          2123 non-null   float64\n",
            " 11  skew              2123 non-null   float64\n",
            " 12  n_peaks           2123 non-null   int64  \n",
            " 13  smooth10_n_peaks  2123 non-null   int64  \n",
            " 14  smooth20_n_peaks  2123 non-null   int64  \n",
            " 15  diff_peaks        2123 non-null   int64  \n",
            " 16  diff2_peaks       2123 non-null   int64  \n",
            " 17  diff_var          2123 non-null   float64\n",
            " 18  diff2_var         2123 non-null   float64\n",
            " 19  gaps_squared      2123 non-null   int64  \n",
            " 20  len_weighted      2123 non-null   int64  \n",
            " 21  var_div_duration  2123 non-null   float64\n",
            " 22  var_div_len       2123 non-null   float64\n",
            "dtypes: float64(9), int64(13), object(1)\n",
            "memory usage: 381.6+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_corr = dataset.drop(['channel'], axis = 1)\n",
        "dataset_corr.corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 789
        },
        "id": "18DZdPu9ZYdM",
        "outputId": "ca84e17e-1672-483c-e552-4f08aaa7dff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   segment   anomaly     train  sampling  duration       len  \\\n",
              "segment           1.000000 -0.133887 -0.009139  0.594096 -0.178043 -0.441953   \n",
              "anomaly          -0.133887  1.000000 -0.013118 -0.267742  0.169642  0.293134   \n",
              "train            -0.009139 -0.013118  1.000000  0.005411 -0.006108 -0.019249   \n",
              "sampling          0.594096 -0.267742  0.005411  1.000000 -0.166177 -0.791557   \n",
              "duration         -0.178043  0.169642 -0.006108 -0.166177  1.000000  0.595424   \n",
              "len              -0.441953  0.293134 -0.019249 -0.791557  0.595424  1.000000   \n",
              "mean             -0.095082 -0.161937  0.005138  0.174819  0.031889 -0.127975   \n",
              "var              -0.072263 -0.185838 -0.008735  0.080157  0.173474 -0.027096   \n",
              "std              -0.036008 -0.173805 -0.002043  0.093727  0.158733 -0.034696   \n",
              "kurtosis          0.048778  0.233905 -0.008455 -0.095661  0.102165  0.126388   \n",
              "skew              0.146115 -0.010606 -0.000815 -0.006657  0.111926  0.045717   \n",
              "n_peaks           0.048461  0.172464 -0.033560 -0.197406  0.172052  0.251524   \n",
              "smooth10_n_peaks -0.175961  0.527219 -0.040088 -0.250290  0.269853  0.380322   \n",
              "smooth20_n_peaks  0.166357  0.132104 -0.061003  0.057668 -0.153259  0.029282   \n",
              "diff_peaks       -0.397870 -0.155948  0.012081 -0.559012  0.342381  0.595271   \n",
              "diff2_peaks      -0.389892 -0.162844  0.015388 -0.566322  0.406555  0.640647   \n",
              "diff_var          0.063709  0.108702 -0.002131  0.161295 -0.098506 -0.144525   \n",
              "diff2_var         0.058242  0.153694  0.000042  0.068812 -0.060116 -0.065919   \n",
              "gaps_squared      0.127228  0.118749  0.015970  0.324512  0.427955 -0.126699   \n",
              "len_weighted     -0.184845  0.156882 -0.005731 -0.144708  0.996448  0.577777   \n",
              "var_div_duration -0.035786 -0.162620 -0.009633  0.095240 -0.011609 -0.104478   \n",
              "var_div_len      -0.012237 -0.127807 -0.007363  0.298552 -0.014797 -0.235295   \n",
              "\n",
              "                      mean       var       std  kurtosis  ...  \\\n",
              "segment          -0.095082 -0.072263 -0.036008  0.048778  ...   \n",
              "anomaly          -0.161937 -0.185838 -0.173805  0.233905  ...   \n",
              "train             0.005138 -0.008735 -0.002043 -0.008455  ...   \n",
              "sampling          0.174819  0.080157  0.093727 -0.095661  ...   \n",
              "duration          0.031889  0.173474  0.158733  0.102165  ...   \n",
              "len              -0.127975 -0.027096 -0.034696  0.126388  ...   \n",
              "mean              1.000000  0.660945  0.737551  0.001821  ...   \n",
              "var               0.660945  1.000000  0.966811  0.052461  ...   \n",
              "std               0.737551  0.966811  1.000000  0.070435  ...   \n",
              "kurtosis          0.001821  0.052461  0.070435  1.000000  ...   \n",
              "skew              0.303368  0.540064  0.616396  0.451002  ...   \n",
              "n_peaks          -0.076865 -0.077554 -0.075185  0.107884  ...   \n",
              "smooth10_n_peaks -0.137341 -0.139595 -0.152962  0.197549  ...   \n",
              "smooth20_n_peaks -0.233126 -0.233402 -0.269941 -0.023397  ...   \n",
              "diff_peaks       -0.175325 -0.150496 -0.173050 -0.054897  ...   \n",
              "diff2_peaks      -0.145729 -0.103837 -0.124226 -0.054359  ...   \n",
              "diff_var          0.319710  0.253804  0.283795  0.115051  ...   \n",
              "diff2_var         0.131407  0.087045  0.111032  0.099874  ...   \n",
              "gaps_squared      0.044103  0.083367  0.076783  0.076696  ...   \n",
              "len_weighted      0.032451  0.171687  0.153972  0.088471  ...   \n",
              "var_div_duration  0.702944  0.903313  0.894202  0.057473  ...   \n",
              "var_div_len       0.661473  0.788910  0.782000  0.051430  ...   \n",
              "\n",
              "                  smooth10_n_peaks  smooth20_n_peaks  diff_peaks  diff2_peaks  \\\n",
              "segment                  -0.175961          0.166357   -0.397870    -0.389892   \n",
              "anomaly                   0.527219          0.132104   -0.155948    -0.162844   \n",
              "train                    -0.040088         -0.061003    0.012081     0.015388   \n",
              "sampling                 -0.250290          0.057668   -0.559012    -0.566322   \n",
              "duration                  0.269853         -0.153259    0.342381     0.406555   \n",
              "len                       0.380322          0.029282    0.595271     0.640647   \n",
              "mean                     -0.137341         -0.233126   -0.175325    -0.145729   \n",
              "var                      -0.139595         -0.233402   -0.150496    -0.103837   \n",
              "std                      -0.152962         -0.269941   -0.173050    -0.124226   \n",
              "kurtosis                  0.197549         -0.023397   -0.054897    -0.054359   \n",
              "skew                     -0.031845         -0.186126   -0.144872    -0.104256   \n",
              "n_peaks                   0.252349          0.062116    0.099797     0.109911   \n",
              "smooth10_n_peaks          1.000000          0.392611   -0.093723    -0.087726   \n",
              "smooth20_n_peaks          0.392611          1.000000   -0.220976    -0.245982   \n",
              "diff_peaks               -0.093723         -0.220976    1.000000     0.973715   \n",
              "diff2_peaks              -0.087726         -0.245982    0.973715     1.000000   \n",
              "diff_var                 -0.026140         -0.092532   -0.119468    -0.135279   \n",
              "diff2_var                 0.004740         -0.039100   -0.051626    -0.063322   \n",
              "gaps_squared             -0.013292         -0.172383   -0.096495    -0.086900   \n",
              "len_weighted              0.272803         -0.145896    0.337998     0.399507   \n",
              "var_div_duration         -0.141288         -0.233328   -0.184280    -0.167969   \n",
              "var_div_len              -0.126984         -0.209519   -0.229448    -0.221803   \n",
              "\n",
              "                  diff_var  diff2_var  gaps_squared  len_weighted  \\\n",
              "segment           0.063709   0.058242      0.127228     -0.184845   \n",
              "anomaly           0.108702   0.153694      0.118749      0.156882   \n",
              "train            -0.002131   0.000042      0.015970     -0.005731   \n",
              "sampling          0.161295   0.068812      0.324512     -0.144708   \n",
              "duration         -0.098506  -0.060116      0.427955      0.996448   \n",
              "len              -0.144525  -0.065919     -0.126699      0.577777   \n",
              "mean              0.319710   0.131407      0.044103      0.032451   \n",
              "var               0.253804   0.087045      0.083367      0.171687   \n",
              "std               0.283795   0.111032      0.076783      0.153972   \n",
              "kurtosis          0.115051   0.099874      0.076696      0.088471   \n",
              "skew              0.173793   0.067566      0.065451      0.092251   \n",
              "n_peaks          -0.014767   0.009869     -0.014590      0.157541   \n",
              "smooth10_n_peaks -0.026140   0.004740     -0.013292      0.272803   \n",
              "smooth20_n_peaks -0.092532  -0.039100     -0.172383     -0.145896   \n",
              "diff_peaks       -0.119468  -0.051626     -0.096495      0.337998   \n",
              "diff2_peaks      -0.135279  -0.063322     -0.086900      0.399507   \n",
              "diff_var          1.000000   0.943615      0.015517     -0.096597   \n",
              "diff2_var         0.943615   1.000000      0.009115     -0.060813   \n",
              "gaps_squared      0.015517   0.009115      1.000000      0.390167   \n",
              "len_weighted     -0.096597  -0.060813      0.390167      1.000000   \n",
              "var_div_duration  0.468248   0.262118      0.001647     -0.012756   \n",
              "var_div_len       0.553193   0.302972      0.074552     -0.005802   \n",
              "\n",
              "                  var_div_duration  var_div_len  \n",
              "segment                  -0.035786    -0.012237  \n",
              "anomaly                  -0.162620    -0.127807  \n",
              "train                    -0.009633    -0.007363  \n",
              "sampling                  0.095240     0.298552  \n",
              "duration                 -0.011609    -0.014797  \n",
              "len                      -0.104478    -0.235295  \n",
              "mean                      0.702944     0.661473  \n",
              "var                       0.903313     0.788910  \n",
              "std                       0.894202     0.782000  \n",
              "kurtosis                  0.057473     0.051430  \n",
              "skew                      0.495024     0.416154  \n",
              "n_peaks                  -0.082066    -0.084224  \n",
              "smooth10_n_peaks         -0.141288    -0.126984  \n",
              "smooth20_n_peaks         -0.233328    -0.209519  \n",
              "diff_peaks               -0.184280    -0.229448  \n",
              "diff2_peaks              -0.167969    -0.221803  \n",
              "diff_var                  0.468248     0.553193  \n",
              "diff2_var                 0.262118     0.302972  \n",
              "gaps_squared              0.001647     0.074552  \n",
              "len_weighted             -0.012756    -0.005802  \n",
              "var_div_duration          1.000000     0.881002  \n",
              "var_div_len               0.881002     1.000000  \n",
              "\n",
              "[22 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e21662a2-a15f-475a-a98e-fdb93cfa468e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>segment</th>\n",
              "      <th>anomaly</th>\n",
              "      <th>train</th>\n",
              "      <th>sampling</th>\n",
              "      <th>duration</th>\n",
              "      <th>len</th>\n",
              "      <th>mean</th>\n",
              "      <th>var</th>\n",
              "      <th>std</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>...</th>\n",
              "      <th>smooth10_n_peaks</th>\n",
              "      <th>smooth20_n_peaks</th>\n",
              "      <th>diff_peaks</th>\n",
              "      <th>diff2_peaks</th>\n",
              "      <th>diff_var</th>\n",
              "      <th>diff2_var</th>\n",
              "      <th>gaps_squared</th>\n",
              "      <th>len_weighted</th>\n",
              "      <th>var_div_duration</th>\n",
              "      <th>var_div_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>segment</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.133887</td>\n",
              "      <td>-0.009139</td>\n",
              "      <td>0.594096</td>\n",
              "      <td>-0.178043</td>\n",
              "      <td>-0.441953</td>\n",
              "      <td>-0.095082</td>\n",
              "      <td>-0.072263</td>\n",
              "      <td>-0.036008</td>\n",
              "      <td>0.048778</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.175961</td>\n",
              "      <td>0.166357</td>\n",
              "      <td>-0.397870</td>\n",
              "      <td>-0.389892</td>\n",
              "      <td>0.063709</td>\n",
              "      <td>0.058242</td>\n",
              "      <td>0.127228</td>\n",
              "      <td>-0.184845</td>\n",
              "      <td>-0.035786</td>\n",
              "      <td>-0.012237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anomaly</th>\n",
              "      <td>-0.133887</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.013118</td>\n",
              "      <td>-0.267742</td>\n",
              "      <td>0.169642</td>\n",
              "      <td>0.293134</td>\n",
              "      <td>-0.161937</td>\n",
              "      <td>-0.185838</td>\n",
              "      <td>-0.173805</td>\n",
              "      <td>0.233905</td>\n",
              "      <td>...</td>\n",
              "      <td>0.527219</td>\n",
              "      <td>0.132104</td>\n",
              "      <td>-0.155948</td>\n",
              "      <td>-0.162844</td>\n",
              "      <td>0.108702</td>\n",
              "      <td>0.153694</td>\n",
              "      <td>0.118749</td>\n",
              "      <td>0.156882</td>\n",
              "      <td>-0.162620</td>\n",
              "      <td>-0.127807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>-0.009139</td>\n",
              "      <td>-0.013118</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.005411</td>\n",
              "      <td>-0.006108</td>\n",
              "      <td>-0.019249</td>\n",
              "      <td>0.005138</td>\n",
              "      <td>-0.008735</td>\n",
              "      <td>-0.002043</td>\n",
              "      <td>-0.008455</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.040088</td>\n",
              "      <td>-0.061003</td>\n",
              "      <td>0.012081</td>\n",
              "      <td>0.015388</td>\n",
              "      <td>-0.002131</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>0.015970</td>\n",
              "      <td>-0.005731</td>\n",
              "      <td>-0.009633</td>\n",
              "      <td>-0.007363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sampling</th>\n",
              "      <td>0.594096</td>\n",
              "      <td>-0.267742</td>\n",
              "      <td>0.005411</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.166177</td>\n",
              "      <td>-0.791557</td>\n",
              "      <td>0.174819</td>\n",
              "      <td>0.080157</td>\n",
              "      <td>0.093727</td>\n",
              "      <td>-0.095661</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.250290</td>\n",
              "      <td>0.057668</td>\n",
              "      <td>-0.559012</td>\n",
              "      <td>-0.566322</td>\n",
              "      <td>0.161295</td>\n",
              "      <td>0.068812</td>\n",
              "      <td>0.324512</td>\n",
              "      <td>-0.144708</td>\n",
              "      <td>0.095240</td>\n",
              "      <td>0.298552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>duration</th>\n",
              "      <td>-0.178043</td>\n",
              "      <td>0.169642</td>\n",
              "      <td>-0.006108</td>\n",
              "      <td>-0.166177</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.595424</td>\n",
              "      <td>0.031889</td>\n",
              "      <td>0.173474</td>\n",
              "      <td>0.158733</td>\n",
              "      <td>0.102165</td>\n",
              "      <td>...</td>\n",
              "      <td>0.269853</td>\n",
              "      <td>-0.153259</td>\n",
              "      <td>0.342381</td>\n",
              "      <td>0.406555</td>\n",
              "      <td>-0.098506</td>\n",
              "      <td>-0.060116</td>\n",
              "      <td>0.427955</td>\n",
              "      <td>0.996448</td>\n",
              "      <td>-0.011609</td>\n",
              "      <td>-0.014797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>len</th>\n",
              "      <td>-0.441953</td>\n",
              "      <td>0.293134</td>\n",
              "      <td>-0.019249</td>\n",
              "      <td>-0.791557</td>\n",
              "      <td>0.595424</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.127975</td>\n",
              "      <td>-0.027096</td>\n",
              "      <td>-0.034696</td>\n",
              "      <td>0.126388</td>\n",
              "      <td>...</td>\n",
              "      <td>0.380322</td>\n",
              "      <td>0.029282</td>\n",
              "      <td>0.595271</td>\n",
              "      <td>0.640647</td>\n",
              "      <td>-0.144525</td>\n",
              "      <td>-0.065919</td>\n",
              "      <td>-0.126699</td>\n",
              "      <td>0.577777</td>\n",
              "      <td>-0.104478</td>\n",
              "      <td>-0.235295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.095082</td>\n",
              "      <td>-0.161937</td>\n",
              "      <td>0.005138</td>\n",
              "      <td>0.174819</td>\n",
              "      <td>0.031889</td>\n",
              "      <td>-0.127975</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.660945</td>\n",
              "      <td>0.737551</td>\n",
              "      <td>0.001821</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.137341</td>\n",
              "      <td>-0.233126</td>\n",
              "      <td>-0.175325</td>\n",
              "      <td>-0.145729</td>\n",
              "      <td>0.319710</td>\n",
              "      <td>0.131407</td>\n",
              "      <td>0.044103</td>\n",
              "      <td>0.032451</td>\n",
              "      <td>0.702944</td>\n",
              "      <td>0.661473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>var</th>\n",
              "      <td>-0.072263</td>\n",
              "      <td>-0.185838</td>\n",
              "      <td>-0.008735</td>\n",
              "      <td>0.080157</td>\n",
              "      <td>0.173474</td>\n",
              "      <td>-0.027096</td>\n",
              "      <td>0.660945</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.966811</td>\n",
              "      <td>0.052461</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.139595</td>\n",
              "      <td>-0.233402</td>\n",
              "      <td>-0.150496</td>\n",
              "      <td>-0.103837</td>\n",
              "      <td>0.253804</td>\n",
              "      <td>0.087045</td>\n",
              "      <td>0.083367</td>\n",
              "      <td>0.171687</td>\n",
              "      <td>0.903313</td>\n",
              "      <td>0.788910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>-0.036008</td>\n",
              "      <td>-0.173805</td>\n",
              "      <td>-0.002043</td>\n",
              "      <td>0.093727</td>\n",
              "      <td>0.158733</td>\n",
              "      <td>-0.034696</td>\n",
              "      <td>0.737551</td>\n",
              "      <td>0.966811</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.070435</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.152962</td>\n",
              "      <td>-0.269941</td>\n",
              "      <td>-0.173050</td>\n",
              "      <td>-0.124226</td>\n",
              "      <td>0.283795</td>\n",
              "      <td>0.111032</td>\n",
              "      <td>0.076783</td>\n",
              "      <td>0.153972</td>\n",
              "      <td>0.894202</td>\n",
              "      <td>0.782000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kurtosis</th>\n",
              "      <td>0.048778</td>\n",
              "      <td>0.233905</td>\n",
              "      <td>-0.008455</td>\n",
              "      <td>-0.095661</td>\n",
              "      <td>0.102165</td>\n",
              "      <td>0.126388</td>\n",
              "      <td>0.001821</td>\n",
              "      <td>0.052461</td>\n",
              "      <td>0.070435</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.197549</td>\n",
              "      <td>-0.023397</td>\n",
              "      <td>-0.054897</td>\n",
              "      <td>-0.054359</td>\n",
              "      <td>0.115051</td>\n",
              "      <td>0.099874</td>\n",
              "      <td>0.076696</td>\n",
              "      <td>0.088471</td>\n",
              "      <td>0.057473</td>\n",
              "      <td>0.051430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skew</th>\n",
              "      <td>0.146115</td>\n",
              "      <td>-0.010606</td>\n",
              "      <td>-0.000815</td>\n",
              "      <td>-0.006657</td>\n",
              "      <td>0.111926</td>\n",
              "      <td>0.045717</td>\n",
              "      <td>0.303368</td>\n",
              "      <td>0.540064</td>\n",
              "      <td>0.616396</td>\n",
              "      <td>0.451002</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.031845</td>\n",
              "      <td>-0.186126</td>\n",
              "      <td>-0.144872</td>\n",
              "      <td>-0.104256</td>\n",
              "      <td>0.173793</td>\n",
              "      <td>0.067566</td>\n",
              "      <td>0.065451</td>\n",
              "      <td>0.092251</td>\n",
              "      <td>0.495024</td>\n",
              "      <td>0.416154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n_peaks</th>\n",
              "      <td>0.048461</td>\n",
              "      <td>0.172464</td>\n",
              "      <td>-0.033560</td>\n",
              "      <td>-0.197406</td>\n",
              "      <td>0.172052</td>\n",
              "      <td>0.251524</td>\n",
              "      <td>-0.076865</td>\n",
              "      <td>-0.077554</td>\n",
              "      <td>-0.075185</td>\n",
              "      <td>0.107884</td>\n",
              "      <td>...</td>\n",
              "      <td>0.252349</td>\n",
              "      <td>0.062116</td>\n",
              "      <td>0.099797</td>\n",
              "      <td>0.109911</td>\n",
              "      <td>-0.014767</td>\n",
              "      <td>0.009869</td>\n",
              "      <td>-0.014590</td>\n",
              "      <td>0.157541</td>\n",
              "      <td>-0.082066</td>\n",
              "      <td>-0.084224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smooth10_n_peaks</th>\n",
              "      <td>-0.175961</td>\n",
              "      <td>0.527219</td>\n",
              "      <td>-0.040088</td>\n",
              "      <td>-0.250290</td>\n",
              "      <td>0.269853</td>\n",
              "      <td>0.380322</td>\n",
              "      <td>-0.137341</td>\n",
              "      <td>-0.139595</td>\n",
              "      <td>-0.152962</td>\n",
              "      <td>0.197549</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.392611</td>\n",
              "      <td>-0.093723</td>\n",
              "      <td>-0.087726</td>\n",
              "      <td>-0.026140</td>\n",
              "      <td>0.004740</td>\n",
              "      <td>-0.013292</td>\n",
              "      <td>0.272803</td>\n",
              "      <td>-0.141288</td>\n",
              "      <td>-0.126984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smooth20_n_peaks</th>\n",
              "      <td>0.166357</td>\n",
              "      <td>0.132104</td>\n",
              "      <td>-0.061003</td>\n",
              "      <td>0.057668</td>\n",
              "      <td>-0.153259</td>\n",
              "      <td>0.029282</td>\n",
              "      <td>-0.233126</td>\n",
              "      <td>-0.233402</td>\n",
              "      <td>-0.269941</td>\n",
              "      <td>-0.023397</td>\n",
              "      <td>...</td>\n",
              "      <td>0.392611</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.220976</td>\n",
              "      <td>-0.245982</td>\n",
              "      <td>-0.092532</td>\n",
              "      <td>-0.039100</td>\n",
              "      <td>-0.172383</td>\n",
              "      <td>-0.145896</td>\n",
              "      <td>-0.233328</td>\n",
              "      <td>-0.209519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diff_peaks</th>\n",
              "      <td>-0.397870</td>\n",
              "      <td>-0.155948</td>\n",
              "      <td>0.012081</td>\n",
              "      <td>-0.559012</td>\n",
              "      <td>0.342381</td>\n",
              "      <td>0.595271</td>\n",
              "      <td>-0.175325</td>\n",
              "      <td>-0.150496</td>\n",
              "      <td>-0.173050</td>\n",
              "      <td>-0.054897</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.093723</td>\n",
              "      <td>-0.220976</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.973715</td>\n",
              "      <td>-0.119468</td>\n",
              "      <td>-0.051626</td>\n",
              "      <td>-0.096495</td>\n",
              "      <td>0.337998</td>\n",
              "      <td>-0.184280</td>\n",
              "      <td>-0.229448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diff2_peaks</th>\n",
              "      <td>-0.389892</td>\n",
              "      <td>-0.162844</td>\n",
              "      <td>0.015388</td>\n",
              "      <td>-0.566322</td>\n",
              "      <td>0.406555</td>\n",
              "      <td>0.640647</td>\n",
              "      <td>-0.145729</td>\n",
              "      <td>-0.103837</td>\n",
              "      <td>-0.124226</td>\n",
              "      <td>-0.054359</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.087726</td>\n",
              "      <td>-0.245982</td>\n",
              "      <td>0.973715</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.135279</td>\n",
              "      <td>-0.063322</td>\n",
              "      <td>-0.086900</td>\n",
              "      <td>0.399507</td>\n",
              "      <td>-0.167969</td>\n",
              "      <td>-0.221803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diff_var</th>\n",
              "      <td>0.063709</td>\n",
              "      <td>0.108702</td>\n",
              "      <td>-0.002131</td>\n",
              "      <td>0.161295</td>\n",
              "      <td>-0.098506</td>\n",
              "      <td>-0.144525</td>\n",
              "      <td>0.319710</td>\n",
              "      <td>0.253804</td>\n",
              "      <td>0.283795</td>\n",
              "      <td>0.115051</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.026140</td>\n",
              "      <td>-0.092532</td>\n",
              "      <td>-0.119468</td>\n",
              "      <td>-0.135279</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.943615</td>\n",
              "      <td>0.015517</td>\n",
              "      <td>-0.096597</td>\n",
              "      <td>0.468248</td>\n",
              "      <td>0.553193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diff2_var</th>\n",
              "      <td>0.058242</td>\n",
              "      <td>0.153694</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>0.068812</td>\n",
              "      <td>-0.060116</td>\n",
              "      <td>-0.065919</td>\n",
              "      <td>0.131407</td>\n",
              "      <td>0.087045</td>\n",
              "      <td>0.111032</td>\n",
              "      <td>0.099874</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004740</td>\n",
              "      <td>-0.039100</td>\n",
              "      <td>-0.051626</td>\n",
              "      <td>-0.063322</td>\n",
              "      <td>0.943615</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.009115</td>\n",
              "      <td>-0.060813</td>\n",
              "      <td>0.262118</td>\n",
              "      <td>0.302972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gaps_squared</th>\n",
              "      <td>0.127228</td>\n",
              "      <td>0.118749</td>\n",
              "      <td>0.015970</td>\n",
              "      <td>0.324512</td>\n",
              "      <td>0.427955</td>\n",
              "      <td>-0.126699</td>\n",
              "      <td>0.044103</td>\n",
              "      <td>0.083367</td>\n",
              "      <td>0.076783</td>\n",
              "      <td>0.076696</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.013292</td>\n",
              "      <td>-0.172383</td>\n",
              "      <td>-0.096495</td>\n",
              "      <td>-0.086900</td>\n",
              "      <td>0.015517</td>\n",
              "      <td>0.009115</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.390167</td>\n",
              "      <td>0.001647</td>\n",
              "      <td>0.074552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>len_weighted</th>\n",
              "      <td>-0.184845</td>\n",
              "      <td>0.156882</td>\n",
              "      <td>-0.005731</td>\n",
              "      <td>-0.144708</td>\n",
              "      <td>0.996448</td>\n",
              "      <td>0.577777</td>\n",
              "      <td>0.032451</td>\n",
              "      <td>0.171687</td>\n",
              "      <td>0.153972</td>\n",
              "      <td>0.088471</td>\n",
              "      <td>...</td>\n",
              "      <td>0.272803</td>\n",
              "      <td>-0.145896</td>\n",
              "      <td>0.337998</td>\n",
              "      <td>0.399507</td>\n",
              "      <td>-0.096597</td>\n",
              "      <td>-0.060813</td>\n",
              "      <td>0.390167</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.012756</td>\n",
              "      <td>-0.005802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>var_div_duration</th>\n",
              "      <td>-0.035786</td>\n",
              "      <td>-0.162620</td>\n",
              "      <td>-0.009633</td>\n",
              "      <td>0.095240</td>\n",
              "      <td>-0.011609</td>\n",
              "      <td>-0.104478</td>\n",
              "      <td>0.702944</td>\n",
              "      <td>0.903313</td>\n",
              "      <td>0.894202</td>\n",
              "      <td>0.057473</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.141288</td>\n",
              "      <td>-0.233328</td>\n",
              "      <td>-0.184280</td>\n",
              "      <td>-0.167969</td>\n",
              "      <td>0.468248</td>\n",
              "      <td>0.262118</td>\n",
              "      <td>0.001647</td>\n",
              "      <td>-0.012756</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.881002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>var_div_len</th>\n",
              "      <td>-0.012237</td>\n",
              "      <td>-0.127807</td>\n",
              "      <td>-0.007363</td>\n",
              "      <td>0.298552</td>\n",
              "      <td>-0.014797</td>\n",
              "      <td>-0.235295</td>\n",
              "      <td>0.661473</td>\n",
              "      <td>0.788910</td>\n",
              "      <td>0.782000</td>\n",
              "      <td>0.051430</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.126984</td>\n",
              "      <td>-0.209519</td>\n",
              "      <td>-0.229448</td>\n",
              "      <td>-0.221803</td>\n",
              "      <td>0.553193</td>\n",
              "      <td>0.302972</td>\n",
              "      <td>0.074552</td>\n",
              "      <td>-0.005802</td>\n",
              "      <td>0.881002</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e21662a2-a15f-475a-a98e-fdb93cfa468e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e21662a2-a15f-475a-a98e-fdb93cfa468e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e21662a2-a15f-475a-a98e-fdb93cfa468e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ca091469-d587-44e1-825b-e586d891466a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca091469-d587-44e1-825b-e586d891466a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ca091469-d587-44e1-825b-e586d891466a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.duplicated()[dataset.duplicated() == True].count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sahwnN3hZYfo",
        "outputId": "daa87fd5-3ba6-455d-ae10-a47def2fd85a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAwIkkUOZYh-",
        "outputId": "aa64dfd5-16ad-4fc2-ca20-38fc4b8242d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "segment             0\n",
            "anomaly             0\n",
            "train               0\n",
            "channel             0\n",
            "sampling            0\n",
            "duration            0\n",
            "len                 0\n",
            "mean                0\n",
            "var                 0\n",
            "std                 0\n",
            "kurtosis            0\n",
            "skew                0\n",
            "n_peaks             0\n",
            "smooth10_n_peaks    0\n",
            "smooth20_n_peaks    0\n",
            "diff_peaks          0\n",
            "diff2_peaks         0\n",
            "diff_var            0\n",
            "diff2_var           0\n",
            "gaps_squared        0\n",
            "len_weighted        0\n",
            "var_div_duration    0\n",
            "var_div_len         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.value_counts(\"anomaly\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT4E21I0ZYkh",
        "outputId": "d74df571-8121-449b-f251-93f6ddbd03f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anomaly\n",
            "0    1689\n",
            "1     434\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = [\n",
        "    \"mean\", \"var\", \"std\", \"len\", \"duration\", \"len_weighted\", \"gaps_squared\", \"n_peaks\",\n",
        "    \"smooth10_n_peaks\", \"smooth20_n_peaks\", \"var_div_duration\", \"var_div_len\",\n",
        "    \"diff_peaks\", \"diff2_peaks\", \"diff_var\", \"diff2_var\", \"kurtosis\", \"skew\",\n",
        "]"
      ],
      "metadata": {
        "id": "F5aFX8tuZYpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = dataset.loc[dataset.train==1, features], dataset.loc[dataset.train==1, \"anomaly\"]\n",
        "X_test, y_test = dataset.loc[dataset.train==0, features], dataset.loc[dataset.train==0, \"anomaly\"]\n",
        "X_train_nominal = dataset.loc[(dataset.anomaly==0)&(dataset.train==1), features]\n",
        "\n",
        "prep = StandardScaler()\n",
        "X_train_nominal2 = prep.fit_transform(X_train_nominal)\n",
        "X_train2 = prep.transform(X_train)\n",
        "X_test2 = prep.transform(X_test)"
      ],
      "metadata": {
        "id": "hicLyBmwrZqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FCNN"
      ],
      "metadata": {
        "id": "yr9HDHWVq4Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "axEuFuaaZYrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = dataset.loc[dataset.train==1, features]\n",
        "y_train = dataset.loc[dataset.train==1, \"anomaly\"]\n",
        "\n",
        "X_test = dataset.loc[dataset.train==0, features]\n",
        "y_test = dataset.loc[dataset.train==0, \"anomaly\"]\n",
        "\n",
        "X_train_nominal = dataset.loc[(dataset.anomaly==0)&(dataset.train==1), features]\n",
        "\n",
        "prep = StandardScaler()\n",
        "X_train_nominal2 = prep.fit_transform(X_train_nominal)\n",
        "X_train2 = prep.transform(X_train)\n",
        "X_test2 = prep.transform(X_test)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train2, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test2, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)"
      ],
      "metadata": {
        "id": "6oksjU9zvauS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "yVCXIXxDvrfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FCNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, dropout):\n",
        "        super(FCNN, self).__init__()\n",
        "        layers = []\n",
        "        in_dim = input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers.append(nn.Linear(in_dim, h))\n",
        "            layers.append(nn.BatchNorm1d(h))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            in_dim = h\n",
        "        layers.append(nn.Linear(in_dim, 1))\n",
        "        layers.append(nn.Sigmoid())  # binary classification\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "jWM6hkVoZYu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "input_dim = X_train_tensor.shape[1]\n",
        "hidden_dims = [128, 64, 32]\n",
        "dropout = 0.2\n",
        "lr = 0.001\n",
        "epochs = 75"
      ],
      "metadata": {
        "id": "qRaUgJW0k6P8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FCNN(input_dim=input_dim, hidden_dims=hidden_dims, dropout=dropout)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "rFbQ3YH1k6SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for xb, yb in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        preds_class = (preds.detach().cpu().numpy() > 0.5).astype(int)\n",
        "        all_preds.extend(preds_class)\n",
        "        all_labels.extend(yb.detach().cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    prec = precision_score(all_labels, all_preds, zero_division=0)\n",
        "    rec = recall_score(all_labels, all_preds, zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(train_loader):.4f}, \"\n",
        "          f\"Acc: {acc:.4f}, Prec: {prec:.4f}, Rec: {rec:.4f}, F1: {f1:.4f}\")\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        preds = model(xb)\n",
        "        preds_class = (preds.cpu().numpy() > 0.5).astype(int)\n",
        "        all_preds.extend(preds_class)\n",
        "        all_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "acc = accuracy_score(all_labels, all_preds)\n",
        "prec = precision_score(all_labels, all_preds, zero_division=0)\n",
        "rec = recall_score(all_labels, all_preds, zero_division=0)\n",
        "f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "\n",
        "print(f\"\\nTest Metrics -> Acc: {acc:.4f}, Prec: {prec:.4f}, Rec: {rec:.4f}, F1: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMbUNbShk6Ux",
        "outputId": "66a6deed-4cc0-40a2-d91b-98b850e340d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75, Loss: 0.5582, Acc: 0.8124, Prec: 0.5333, Rec: 0.5483, F1: 0.5407\n",
            "Epoch 2/75, Loss: 0.4455, Acc: 0.9040, Prec: 0.9286, Rec: 0.5670, F1: 0.7041\n",
            "Epoch 3/75, Loss: 0.3754, Acc: 0.9040, Prec: 0.9421, Rec: 0.5576, F1: 0.7006\n",
            "Epoch 4/75, Loss: 0.3209, Acc: 0.9122, Prec: 0.9289, Rec: 0.6106, F1: 0.7368\n",
            "Epoch 5/75, Loss: 0.2836, Acc: 0.9141, Prec: 0.9220, Rec: 0.6262, F1: 0.7458\n",
            "Epoch 6/75, Loss: 0.2457, Acc: 0.9266, Prec: 0.9016, Rec: 0.7134, F1: 0.7965\n",
            "Epoch 7/75, Loss: 0.2218, Acc: 0.9360, Prec: 0.9041, Rec: 0.7632, F1: 0.8277\n",
            "Epoch 8/75, Loss: 0.2012, Acc: 0.9366, Prec: 0.9135, Rec: 0.7570, F1: 0.8279\n",
            "Epoch 9/75, Loss: 0.1987, Acc: 0.9329, Prec: 0.8639, Rec: 0.7913, F1: 0.8260\n",
            "Epoch 10/75, Loss: 0.1897, Acc: 0.9391, Prec: 0.8916, Rec: 0.7944, F1: 0.8402\n",
            "Epoch 11/75, Loss: 0.1827, Acc: 0.9379, Prec: 0.8936, Rec: 0.7850, F1: 0.8358\n",
            "Epoch 12/75, Loss: 0.1605, Acc: 0.9442, Prec: 0.9028, Rec: 0.8100, F1: 0.8539\n",
            "Epoch 13/75, Loss: 0.1450, Acc: 0.9523, Prec: 0.9298, Rec: 0.8255, F1: 0.8746\n",
            "Epoch 14/75, Loss: 0.1415, Acc: 0.9517, Prec: 0.9094, Rec: 0.8442, F1: 0.8756\n",
            "Epoch 15/75, Loss: 0.1530, Acc: 0.9492, Prec: 0.9255, Rec: 0.8131, F1: 0.8657\n",
            "Epoch 16/75, Loss: 0.1373, Acc: 0.9504, Prec: 0.9116, Rec: 0.8349, F1: 0.8715\n",
            "Epoch 17/75, Loss: 0.1454, Acc: 0.9529, Prec: 0.9424, Rec: 0.8162, F1: 0.8748\n",
            "Epoch 18/75, Loss: 0.1397, Acc: 0.9555, Prec: 0.9340, Rec: 0.8380, F1: 0.8834\n",
            "Epoch 19/75, Loss: 0.1321, Acc: 0.9548, Prec: 0.9278, Rec: 0.8411, F1: 0.8824\n",
            "Epoch 20/75, Loss: 0.1289, Acc: 0.9567, Prec: 0.9257, Rec: 0.8536, F1: 0.8882\n",
            "Epoch 21/75, Loss: 0.1287, Acc: 0.9548, Prec: 0.9249, Rec: 0.8442, F1: 0.8827\n",
            "Epoch 22/75, Loss: 0.1299, Acc: 0.9517, Prec: 0.9067, Rec: 0.8474, F1: 0.8760\n",
            "Epoch 23/75, Loss: 0.1362, Acc: 0.9536, Prec: 0.9273, Rec: 0.8349, F1: 0.8787\n",
            "Epoch 24/75, Loss: 0.1174, Acc: 0.9573, Prec: 0.9377, Rec: 0.8442, F1: 0.8885\n",
            "Epoch 25/75, Loss: 0.1228, Acc: 0.9573, Prec: 0.9408, Rec: 0.8411, F1: 0.8882\n",
            "Epoch 26/75, Loss: 0.1208, Acc: 0.9542, Prec: 0.9079, Rec: 0.8598, F1: 0.8832\n",
            "Epoch 27/75, Loss: 0.1135, Acc: 0.9617, Prec: 0.9392, Rec: 0.8660, F1: 0.9011\n",
            "Epoch 28/75, Loss: 0.1193, Acc: 0.9617, Prec: 0.9392, Rec: 0.8660, F1: 0.9011\n",
            "Epoch 29/75, Loss: 0.1135, Acc: 0.9573, Prec: 0.9470, Rec: 0.8349, F1: 0.8874\n",
            "Epoch 30/75, Loss: 0.1176, Acc: 0.9555, Prec: 0.9139, Rec: 0.8598, F1: 0.8860\n",
            "Epoch 31/75, Loss: 0.1112, Acc: 0.9580, Prec: 0.9635, Rec: 0.8224, F1: 0.8874\n",
            "Epoch 32/75, Loss: 0.1163, Acc: 0.9548, Prec: 0.9192, Rec: 0.8505, F1: 0.8835\n",
            "Epoch 33/75, Loss: 0.1054, Acc: 0.9573, Prec: 0.9259, Rec: 0.8567, F1: 0.8900\n",
            "Epoch 34/75, Loss: 0.1062, Acc: 0.9624, Prec: 0.9424, Rec: 0.8660, F1: 0.9026\n",
            "Epoch 35/75, Loss: 0.1184, Acc: 0.9561, Prec: 0.9373, Rec: 0.8380, F1: 0.8849\n",
            "Epoch 36/75, Loss: 0.1239, Acc: 0.9561, Prec: 0.9343, Rec: 0.8411, F1: 0.8852\n",
            "Epoch 37/75, Loss: 0.1056, Acc: 0.9624, Prec: 0.9485, Rec: 0.8598, F1: 0.9020\n",
            "Epoch 38/75, Loss: 0.1104, Acc: 0.9605, Prec: 0.9329, Rec: 0.8660, F1: 0.8982\n",
            "Epoch 39/75, Loss: 0.1168, Acc: 0.9542, Prec: 0.9397, Rec: 0.8255, F1: 0.8789\n",
            "Epoch 40/75, Loss: 0.1001, Acc: 0.9642, Prec: 0.9400, Rec: 0.8785, F1: 0.9082\n",
            "Epoch 41/75, Loss: 0.1056, Acc: 0.9636, Prec: 0.9550, Rec: 0.8598, F1: 0.9049\n",
            "Epoch 42/75, Loss: 0.1203, Acc: 0.9561, Prec: 0.9343, Rec: 0.8411, F1: 0.8852\n",
            "Epoch 43/75, Loss: 0.1024, Acc: 0.9630, Prec: 0.9517, Rec: 0.8598, F1: 0.9034\n",
            "Epoch 44/75, Loss: 0.1186, Acc: 0.9611, Prec: 0.9512, Rec: 0.8505, F1: 0.8980\n",
            "Epoch 45/75, Loss: 0.1039, Acc: 0.9598, Prec: 0.9298, Rec: 0.8660, F1: 0.8968\n",
            "Epoch 46/75, Loss: 0.1053, Acc: 0.9611, Prec: 0.9390, Rec: 0.8629, F1: 0.8994\n",
            "Epoch 47/75, Loss: 0.0996, Acc: 0.9699, Prec: 0.9723, Rec: 0.8754, F1: 0.9213\n",
            "Epoch 48/75, Loss: 0.1047, Acc: 0.9655, Prec: 0.9463, Rec: 0.8785, F1: 0.9111\n",
            "Epoch 49/75, Loss: 0.1031, Acc: 0.9636, Prec: 0.9428, Rec: 0.8723, F1: 0.9061\n",
            "Epoch 50/75, Loss: 0.1042, Acc: 0.9617, Prec: 0.9422, Rec: 0.8629, F1: 0.9008\n",
            "Epoch 51/75, Loss: 0.1021, Acc: 0.9636, Prec: 0.9582, Rec: 0.8567, F1: 0.9046\n",
            "Epoch 52/75, Loss: 0.1019, Acc: 0.9617, Prec: 0.9392, Rec: 0.8660, F1: 0.9011\n",
            "Epoch 53/75, Loss: 0.1007, Acc: 0.9611, Prec: 0.9390, Rec: 0.8629, F1: 0.8994\n",
            "Epoch 54/75, Loss: 0.1039, Acc: 0.9611, Prec: 0.9331, Rec: 0.8692, F1: 0.9000\n",
            "Epoch 55/75, Loss: 0.1098, Acc: 0.9598, Prec: 0.9356, Rec: 0.8598, F1: 0.8961\n",
            "Epoch 56/75, Loss: 0.1022, Acc: 0.9636, Prec: 0.9519, Rec: 0.8629, F1: 0.9052\n",
            "Epoch 57/75, Loss: 0.0945, Acc: 0.9630, Prec: 0.9456, Rec: 0.8660, F1: 0.9041\n",
            "Epoch 58/75, Loss: 0.1063, Acc: 0.9580, Prec: 0.9178, Rec: 0.8692, F1: 0.8928\n",
            "Epoch 59/75, Loss: 0.1004, Acc: 0.9611, Prec: 0.9274, Rec: 0.8754, F1: 0.9006\n",
            "Epoch 60/75, Loss: 0.1053, Acc: 0.9586, Prec: 0.9322, Rec: 0.8567, F1: 0.8929\n",
            "Epoch 61/75, Loss: 0.1041, Acc: 0.9642, Prec: 0.9748, Rec: 0.8442, F1: 0.9048\n",
            "Epoch 62/75, Loss: 0.0967, Acc: 0.9624, Prec: 0.9336, Rec: 0.8754, F1: 0.9035\n",
            "Epoch 63/75, Loss: 0.0996, Acc: 0.9630, Prec: 0.9456, Rec: 0.8660, F1: 0.9041\n",
            "Epoch 64/75, Loss: 0.1000, Acc: 0.9649, Prec: 0.9553, Rec: 0.8660, F1: 0.9085\n",
            "Epoch 65/75, Loss: 0.1003, Acc: 0.9636, Prec: 0.9398, Rec: 0.8754, F1: 0.9065\n",
            "Epoch 66/75, Loss: 0.0869, Acc: 0.9636, Prec: 0.9550, Rec: 0.8598, F1: 0.9049\n",
            "Epoch 67/75, Loss: 0.1001, Acc: 0.9580, Prec: 0.9291, Rec: 0.8567, F1: 0.8914\n",
            "Epoch 68/75, Loss: 0.0938, Acc: 0.9636, Prec: 0.9340, Rec: 0.8816, F1: 0.9071\n",
            "Epoch 69/75, Loss: 0.1060, Acc: 0.9636, Prec: 0.9398, Rec: 0.8754, F1: 0.9065\n",
            "Epoch 70/75, Loss: 0.0939, Acc: 0.9693, Prec: 0.9658, Rec: 0.8785, F1: 0.9201\n",
            "Epoch 71/75, Loss: 0.0842, Acc: 0.9705, Prec: 0.9567, Rec: 0.8941, F1: 0.9243\n",
            "Epoch 72/75, Loss: 0.0937, Acc: 0.9630, Prec: 0.9338, Rec: 0.8785, F1: 0.9053\n",
            "Epoch 73/75, Loss: 0.0869, Acc: 0.9674, Prec: 0.9529, Rec: 0.8816, F1: 0.9159\n",
            "Epoch 74/75, Loss: 0.0909, Acc: 0.9668, Prec: 0.9497, Rec: 0.8816, F1: 0.9144\n",
            "Epoch 75/75, Loss: 0.0942, Acc: 0.9642, Prec: 0.9459, Rec: 0.8723, F1: 0.9076\n",
            "\n",
            "Test Metrics -> Acc: 0.9811, Prec: 0.9640, Rec: 0.9469, F1: 0.9554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.jit.load(\"fcnn_model.pt\", map_location=\"cpu\")\n",
        "scripted_model = torch.jit.script(model)\n",
        "scripted_model.save(\"fcnn_model.pt\")\n",
        "joblib.dump(prep, \"scaler.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOO6b2D-k6XX",
        "outputId": "52eb7727-4714-4ef1-c63d-9b9f7996ad2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RpBBMOFprGcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Epoch 1/75, Loss: 0.6888, Acc: 0.5326, Prec: 0.2740, Rec: 0.8006, F1: 0.4083\n",
        "Epoch 2/75, Loss: 0.5124, Acc: 0.8582, Prec: 0.6518, Rec: 0.6355, F1: 0.6435\n",
        "Epoch 3/75, Loss: 0.4383, Acc: 0.8946, Prec: 0.8283, Rec: 0.6012, F1: 0.6968\n",
        "Epoch 4/75, Loss: 0.3774, Acc: 0.9059, Prec: 0.8904, Rec: 0.6075, F1: 0.7222\n",
        "Epoch 5/75, Loss: 0.3235, Acc: 0.9109, Prec: 0.8714, Rec: 0.6542, F1: 0.7473\n",
        "Epoch 6/75, Loss: 0.2946, Acc: 0.9172, Prec: 0.8795, Rec: 0.6822, F1: 0.7684\n",
        "Epoch 7/75, Loss: 0.2632, Acc: 0.9210, Prec: 0.8679, Rec: 0.7165, F1: 0.7850\n",
        "Epoch 8/75, Loss: 0.2450, Acc: 0.9253, Prec: 0.8976, Rec: 0.7103, F1: 0.7930\n",
        "Epoch 9/75, Loss: 0.2201, Acc: 0.9304, Prec: 0.8646, Rec: 0.7757, F1: 0.8177\n",
        "Epoch 10/75, Loss: 0.2242, Acc: 0.9266, Prec: 0.8723, Rec: 0.7445, F1: 0.8034\n",
        "Epoch 11/75, Loss: 0.2092, Acc: 0.9316, Prec: 0.8759, Rec: 0.7695, F1: 0.8192\n",
        "Epoch 12/75, Loss: 0.1899, Acc: 0.9373, Prec: 0.9018, Rec: 0.7726, F1: 0.8322\n",
        "Epoch 13/75, Loss: 0.1852, Acc: 0.9454, Prec: 0.9091, Rec: 0.8100, F1: 0.8567\n",
        "Epoch 14/75, Loss: 0.1759, Acc: 0.9442, Prec: 0.9000, Rec: 0.8131, F1: 0.8543\n",
        "Epoch 15/75, Loss: 0.1743, Acc: 0.9366, Prec: 0.8819, Rec: 0.7913, F1: 0.8342\n",
        "Epoch 16/75, Loss: 0.1732, Acc: 0.9460, Prec: 0.9304, Rec: 0.7913, F1: 0.8552\n",
        "Epoch 17/75, Loss: 0.1526, Acc: 0.9435, Prec: 0.8997, Rec: 0.8100, F1: 0.8525\n",
        "Epoch 18/75, Loss: 0.1765, Acc: 0.9366, Prec: 0.8793, Rec: 0.7944, F1: 0.8347\n",
        "Epoch 19/75, Loss: 0.1603, Acc: 0.9442, Prec: 0.8893, Rec: 0.8255, F1: 0.8562\n",
        "Epoch 20/75, Loss: 0.1463, Acc: 0.9517, Prec: 0.9150, Rec: 0.8380, F1: 0.8748\n",
        "Epoch 21/75, Loss: 0.1613, Acc: 0.9486, Prec: 0.9283, Rec: 0.8069, F1: 0.8633\n",
        "Epoch 22/75, Loss: 0.1517, Acc: 0.9460, Prec: 0.8930, Rec: 0.8318, F1: 0.8613\n",
        "Epoch 23/75, Loss: 0.1470, Acc: 0.9517, Prec: 0.9266, Rec: 0.8255, F1: 0.8731\n",
        "Epoch 24/75, Loss: 0.1493, Acc: 0.9467, Prec: 0.9041, Rec: 0.8224, F1: 0.8613\n",
        "Epoch 25/75, Loss: 0.1498, Acc: 0.9467, Prec: 0.8986, Rec: 0.8287, F1: 0.8622\n",
        "Epoch 26/75, Loss: 0.1368, Acc: 0.9523, Prec: 0.9268, Rec: 0.8287, F1: 0.8750\n",
        "Epoch 27/75, Loss: 0.1387, Acc: 0.9555, Prec: 0.9139, Rec: 0.8598, F1: 0.8860\n",
        "Epoch 28/75, Loss: 0.1408, Acc: 0.9492, Prec: 0.9027, Rec: 0.8380, F1: 0.8691\n",
        "Epoch 29/75, Loss: 0.1250, Acc: 0.9605, Prec: 0.9358, Rec: 0.8629, F1: 0.8979\n",
        "Epoch 30/75, Loss: 0.1337, Acc: 0.9561, Prec: 0.9373, Rec: 0.8380, F1: 0.8849\n",
        "Epoch 31/75, Loss: 0.1451, Acc: 0.9492, Prec: 0.9027, Rec: 0.8380, F1: 0.8691\n",
        "Epoch 32/75, Loss: 0.1385, Acc: 0.9529, Prec: 0.9301, Rec: 0.8287, F1: 0.8764\n",
        "Epoch 33/75, Loss: 0.1398, Acc: 0.9504, Prec: 0.9231, Rec: 0.8224, F1: 0.8699\n",
        "Epoch 34/75, Loss: 0.1220, Acc: 0.9567, Prec: 0.9118, Rec: 0.8692, F1: 0.8900\n",
        "Epoch 35/75, Loss: 0.1317, Acc: 0.9511, Prec: 0.9204, Rec: 0.8287, F1: 0.8721\n",
        "Epoch 36/75, Loss: 0.1369, Acc: 0.9523, Prec: 0.8990, Rec: 0.8598, F1: 0.8790\n",
        "Epoch 37/75, Loss: 0.1399, Acc: 0.9536, Prec: 0.9273, Rec: 0.8349, F1: 0.8787\n",
        "Epoch 38/75, Loss: 0.1292, Acc: 0.9536, Prec: 0.9186, Rec: 0.8442, F1: 0.8799\n",
        "Epoch 39/75, Loss: 0.1295, Acc: 0.9536, Prec: 0.9186, Rec: 0.8442, F1: 0.8799\n",
        "Epoch 40/75, Loss: 0.1258, Acc: 0.9555, Prec: 0.9167, Rec: 0.8567, F1: 0.8857\n",
        "Epoch 41/75, Loss: 0.1308, Acc: 0.9567, Prec: 0.9228, Rec: 0.8567, F1: 0.8885\n",
        "Epoch 42/75, Loss: 0.1368, Acc: 0.9523, Prec: 0.9268, Rec: 0.8287, F1: 0.8750\n",
        "Epoch 43/75, Loss: 0.1361, Acc: 0.9561, Prec: 0.9343, Rec: 0.8411, F1: 0.8852\n",
        "Epoch 44/75, Loss: 0.1284, Acc: 0.9523, Prec: 0.9097, Rec: 0.8474, F1: 0.8774\n",
        "Epoch 45/75, Loss: 0.1243, Acc: 0.9605, Prec: 0.9216, Rec: 0.8785, F1: 0.8995\n",
        "Epoch 46/75, Loss: 0.1246, Acc: 0.9517, Prec: 0.9150, Rec: 0.8380, F1: 0.8748\n",
        "Epoch 47/75, Loss: 0.1257, Acc: 0.9542, Prec: 0.9218, Rec: 0.8442, F1: 0.8813\n",
        "Epoch 48/75, Loss: 0.1203, Acc: 0.9580, Prec: 0.9262, Rec: 0.8598, F1: 0.8918\n",
        "Epoch 49/75, Loss: 0.1302, Acc: 0.9567, Prec: 0.9228, Rec: 0.8567, F1: 0.8885\n",
        "Epoch 50/75, Loss: 0.1321, Acc: 0.9536, Prec: 0.9076, Rec: 0.8567, F1: 0.8814\n",
        "Epoch 51/75, Loss: 0.1244, Acc: 0.9542, Prec: 0.9079, Rec: 0.8598, F1: 0.8832\n",
        "Epoch 52/75, Loss: 0.1145, Acc: 0.9580, Prec: 0.9379, Rec: 0.8474, F1: 0.8903\n",
        "Epoch 53/75, Loss: 0.1119, Acc: 0.9598, Prec: 0.9356, Rec: 0.8598, F1: 0.8961\n",
        "Epoch 54/75, Loss: 0.1279, Acc: 0.9529, Prec: 0.9271, Rec: 0.8318, F1: 0.8768\n",
        "Epoch 55/75, Loss: 0.1181, Acc: 0.9573, Prec: 0.9259, Rec: 0.8567, F1: 0.8900\n",
        "Epoch 56/75, Loss: 0.1181, Acc: 0.9548, Prec: 0.9192, Rec: 0.8505, F1: 0.8835\n",
        "Epoch 57/75, Loss: 0.1174, Acc: 0.9573, Prec: 0.9439, Rec: 0.8380, F1: 0.8878\n",
        "Epoch 58/75, Loss: 0.1149, Acc: 0.9580, Prec: 0.9320, Rec: 0.8536, F1: 0.8911\n",
        "Epoch 59/75, Loss: 0.1252, Acc: 0.9548, Prec: 0.9082, Rec: 0.8629, F1: 0.8850\n",
        "Epoch 60/75, Loss: 0.1264, Acc: 0.9536, Prec: 0.9215, Rec: 0.8411, F1: 0.8795\n",
        "Epoch 61/75, Loss: 0.1219, Acc: 0.9580, Prec: 0.9410, Rec: 0.8442, F1: 0.8900\n",
        "Epoch 62/75, Loss: 0.1119, Acc: 0.9636, Prec: 0.9398, Rec: 0.8754, F1: 0.9065\n",
        "Epoch 63/75, Loss: 0.1261, Acc: 0.9529, Prec: 0.9100, Rec: 0.8505, F1: 0.8792\n",
        "Epoch 64/75, Loss: 0.1042, Acc: 0.9624, Prec: 0.9454, Rec: 0.8629, F1: 0.9023\n",
        "Epoch 65/75, Loss: 0.1087, Acc: 0.9624, Prec: 0.9454, Rec: 0.8629, F1: 0.9023\n",
        "Epoch 66/75, Loss: 0.1056, Acc: 0.9624, Prec: 0.9485, Rec: 0.8598, F1: 0.9020\n",
        "Epoch 67/75, Loss: 0.1184, Acc: 0.9555, Prec: 0.9281, Rec: 0.8442, F1: 0.8842\n",
        "Epoch 68/75, Loss: 0.0949, Acc: 0.9611, Prec: 0.9331, Rec: 0.8692, F1: 0.9000\n",
        "Epoch 69/75, Loss: 0.1135, Acc: 0.9617, Prec: 0.9362, Rec: 0.8692, F1: 0.9015\n",
        "Epoch 70/75, Loss: 0.1004, Acc: 0.9624, Prec: 0.9365, Rec: 0.8723, F1: 0.9032\n",
        "Epoch 71/75, Loss: 0.1072, Acc: 0.9668, Prec: 0.9408, Rec: 0.8910, F1: 0.9152\n",
        "Epoch 72/75, Loss: 0.1146, Acc: 0.9617, Prec: 0.9483, Rec: 0.8567, F1: 0.9002\n",
        "Epoch 73/75, Loss: 0.1126, Acc: 0.9592, Prec: 0.9354, Rec: 0.8567, F1: 0.8943\n",
        "Epoch 74/75, Loss: 0.0966, Acc: 0.9630, Prec: 0.9456, Rec: 0.8660, F1: 0.9041\n",
        "Epoch 75/75, Loss: 0.1035, Acc: 0.9617, Prec: 0.9452, Rec: 0.8598, F1: 0.9005\n",
        "\n",
        "Test Metrics -> Acc: 0.9754, Prec: 0.9630, Rec: 0.9204, F1: 0.9412\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "input_dim = X_train_tensor.shape[1]\n",
        "hidden_dims = [128, 64, 32]\n",
        "dropout = 0.3\n",
        "lr = 0.001\n",
        "epochs = 75\n",
        "\n",
        "8 saniye\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aSFHg4Iry31e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Epoch 1/75, Loss: 0.5449, Acc: 0.8394, Prec: 0.6484, Rec: 0.4424, F1: 0.5259\n",
        "Epoch 2/75, Loss: 0.4098, Acc: 0.8990, Prec: 0.9444, Rec: 0.5296, F1: 0.6786\n",
        "Epoch 3/75, Loss: 0.3364, Acc: 0.9009, Prec: 0.9358, Rec: 0.5452, F1: 0.6890\n",
        "Epoch 4/75, Loss: 0.2953, Acc: 0.9109, Prec: 0.9497, Rec: 0.5888, F1: 0.7269\n",
        "Epoch 5/75, Loss: 0.2561, Acc: 0.9159, Prec: 0.9390, Rec: 0.6231, F1: 0.7491\n",
        "Epoch 6/75, Loss: 0.2339, Acc: 0.9228, Prec: 0.9231, Rec: 0.6729, F1: 0.7784\n",
        "Epoch 7/75, Loss: 0.2154, Acc: 0.9285, Prec: 0.8996, Rec: 0.7259, F1: 0.8034\n",
        "Epoch 8/75, Loss: 0.1950, Acc: 0.9348, Prec: 0.8974, Rec: 0.7632, F1: 0.8249\n",
        "Epoch 9/75, Loss: 0.1976, Acc: 0.9366, Prec: 0.8873, Rec: 0.7850, F1: 0.8331\n",
        "Epoch 10/75, Loss: 0.1787, Acc: 0.9354, Prec: 0.9098, Rec: 0.7539, F1: 0.8245\n",
        "Epoch 11/75, Loss: 0.1627, Acc: 0.9498, Prec: 0.9141, Rec: 0.8287, F1: 0.8693\n",
        "Epoch 12/75, Loss: 0.1647, Acc: 0.9473, Prec: 0.9129, Rec: 0.8162, F1: 0.8618\n",
        "Epoch 13/75, Loss: 0.1560, Acc: 0.9454, Prec: 0.9062, Rec: 0.8131, F1: 0.8571\n",
        "Epoch 14/75, Loss: 0.1522, Acc: 0.9473, Prec: 0.9158, Rec: 0.8131, F1: 0.8614\n",
        "Epoch 15/75, Loss: 0.1484, Acc: 0.9473, Prec: 0.9044, Rec: 0.8255, F1: 0.8632\n",
        "Epoch 16/75, Loss: 0.1501, Acc: 0.9454, Prec: 0.9179, Rec: 0.8006, F1: 0.8552\n",
        "Epoch 17/75, Loss: 0.1499, Acc: 0.9548, Prec: 0.9338, Rec: 0.8349, F1: 0.8816\n",
        "Epoch 18/75, Loss: 0.1418, Acc: 0.9498, Prec: 0.9141, Rec: 0.8287, F1: 0.8693\n",
        "Epoch 19/75, Loss: 0.1332, Acc: 0.9561, Prec: 0.9373, Rec: 0.8380, F1: 0.8849\n",
        "Epoch 20/75, Loss: 0.1358, Acc: 0.9523, Prec: 0.9181, Rec: 0.8380, F1: 0.8762\n",
        "Epoch 21/75, Loss: 0.1229, Acc: 0.9592, Prec: 0.9414, Rec: 0.8505, F1: 0.8936\n",
        "Epoch 22/75, Loss: 0.1289, Acc: 0.9555, Prec: 0.9371, Rec: 0.8349, F1: 0.8830\n",
        "Epoch 23/75, Loss: 0.1233, Acc: 0.9548, Prec: 0.9109, Rec: 0.8598, F1: 0.8846\n",
        "Epoch 24/75, Loss: 0.1198, Acc: 0.9580, Prec: 0.9536, Rec: 0.8318, F1: 0.8885\n",
        "Epoch 25/75, Loss: 0.1324, Acc: 0.9536, Prec: 0.8997, Rec: 0.8660, F1: 0.8825\n",
        "Epoch 26/75, Loss: 0.1206, Acc: 0.9598, Prec: 0.9573, Rec: 0.8380, F1: 0.8937\n",
        "Epoch 27/75, Loss: 0.1222, Acc: 0.9567, Prec: 0.9118, Rec: 0.8692, F1: 0.8900\n",
        "Epoch 28/75, Loss: 0.1144, Acc: 0.9617, Prec: 0.9643, Rec: 0.8411, F1: 0.8985\n",
        "Epoch 29/75, Loss: 0.1111, Acc: 0.9592, Prec: 0.9295, Rec: 0.8629, F1: 0.8950\n",
        "Epoch 30/75, Loss: 0.1176, Acc: 0.9630, Prec: 0.9517, Rec: 0.8598, F1: 0.9034\n",
        "Epoch 31/75, Loss: 0.1100, Acc: 0.9636, Prec: 0.9369, Rec: 0.8785, F1: 0.9068\n",
        "Epoch 32/75, Loss: 0.1099, Acc: 0.9617, Prec: 0.9514, Rec: 0.8536, F1: 0.8998\n",
        "Epoch 33/75, Loss: 0.1228, Acc: 0.9586, Prec: 0.9264, Rec: 0.8629, F1: 0.8935\n",
        "Epoch 34/75, Loss: 0.1125, Acc: 0.9611, Prec: 0.9450, Rec: 0.8567, F1: 0.8987\n",
        "Epoch 35/75, Loss: 0.1053, Acc: 0.9624, Prec: 0.9454, Rec: 0.8629, F1: 0.9023\n",
        "Epoch 36/75, Loss: 0.1112, Acc: 0.9592, Prec: 0.9324, Rec: 0.8598, F1: 0.8947\n",
        "Epoch 37/75, Loss: 0.1018, Acc: 0.9624, Prec: 0.9547, Rec: 0.8536, F1: 0.9013\n",
        "Epoch 38/75, Loss: 0.1130, Acc: 0.9586, Prec: 0.9474, Rec: 0.8411, F1: 0.8911\n",
        "Epoch 39/75, Loss: 0.1067, Acc: 0.9611, Prec: 0.9191, Rec: 0.8847, F1: 0.9016\n",
        "Epoch 40/75, Loss: 0.1020, Acc: 0.9617, Prec: 0.9248, Rec: 0.8816, F1: 0.9027\n",
        "Epoch 41/75, Loss: 0.1085, Acc: 0.9649, Prec: 0.9649, Rec: 0.8567, F1: 0.9076\n",
        "Epoch 42/75, Loss: 0.1155, Acc: 0.9580, Prec: 0.9349, Rec: 0.8505, F1: 0.8907\n",
        "Epoch 43/75, Loss: 0.1033, Acc: 0.9592, Prec: 0.9414, Rec: 0.8505, F1: 0.8936\n",
        "Epoch 44/75, Loss: 0.1055, Acc: 0.9567, Prec: 0.9257, Rec: 0.8536, F1: 0.8882\n",
        "Epoch 45/75, Loss: 0.1014, Acc: 0.9611, Prec: 0.9576, Rec: 0.8442, F1: 0.8974\n",
        "Epoch 46/75, Loss: 0.1026, Acc: 0.9580, Prec: 0.9320, Rec: 0.8536, F1: 0.8911\n",
        "Epoch 47/75, Loss: 0.1038, Acc: 0.9642, Prec: 0.9459, Rec: 0.8723, F1: 0.9076\n",
        "Epoch 48/75, Loss: 0.1027, Acc: 0.9611, Prec: 0.9390, Rec: 0.8629, F1: 0.8994\n",
        "Epoch 49/75, Loss: 0.0993, Acc: 0.9636, Prec: 0.9488, Rec: 0.8660, F1: 0.9055\n",
        "Epoch 50/75, Loss: 0.1148, Acc: 0.9630, Prec: 0.9367, Rec: 0.8754, F1: 0.9050\n",
        "Epoch 51/75, Loss: 0.1085, Acc: 0.9592, Prec: 0.9324, Rec: 0.8598, F1: 0.8947\n",
        "Epoch 52/75, Loss: 0.0955, Acc: 0.9661, Prec: 0.9556, Rec: 0.8723, F1: 0.9121\n",
        "Epoch 53/75, Loss: 0.1027, Acc: 0.9611, Prec: 0.9390, Rec: 0.8629, F1: 0.8994\n",
        "Epoch 54/75, Loss: 0.0936, Acc: 0.9668, Prec: 0.9408, Rec: 0.8910, F1: 0.9152\n",
        "Epoch 55/75, Loss: 0.0996, Acc: 0.9592, Prec: 0.9384, Rec: 0.8536, F1: 0.8940\n",
        "Epoch 56/75, Loss: 0.0971, Acc: 0.9655, Prec: 0.9586, Rec: 0.8660, F1: 0.9100\n",
        "Epoch 57/75, Loss: 0.0981, Acc: 0.9592, Prec: 0.9414, Rec: 0.8505, F1: 0.8936\n",
        "Epoch 58/75, Loss: 0.0999, Acc: 0.9636, Prec: 0.9256, Rec: 0.8910, F1: 0.9079\n",
        "Epoch 59/75, Loss: 0.1002, Acc: 0.9624, Prec: 0.9365, Rec: 0.8723, F1: 0.9032\n",
        "Epoch 60/75, Loss: 0.0871, Acc: 0.9668, Prec: 0.9467, Rec: 0.8847, F1: 0.9147\n",
        "Epoch 61/75, Loss: 0.1016, Acc: 0.9592, Prec: 0.9507, Rec: 0.8411, F1: 0.8926\n",
        "Epoch 62/75, Loss: 0.0960, Acc: 0.9655, Prec: 0.9404, Rec: 0.8847, F1: 0.9117\n",
        "Epoch 63/75, Loss: 0.0921, Acc: 0.9674, Prec: 0.9498, Rec: 0.8847, F1: 0.9161\n",
        "Epoch 64/75, Loss: 0.0964, Acc: 0.9649, Prec: 0.9461, Rec: 0.8754, F1: 0.9094\n",
        "Epoch 65/75, Loss: 0.0922, Acc: 0.9680, Prec: 0.9500, Rec: 0.8879, F1: 0.9179\n",
        "Epoch 66/75, Loss: 0.0890, Acc: 0.9674, Prec: 0.9439, Rec: 0.8910, F1: 0.9167\n",
        "Epoch 67/75, Loss: 0.0847, Acc: 0.9661, Prec: 0.9525, Rec: 0.8754, F1: 0.9123\n",
        "Epoch 68/75, Loss: 0.0967, Acc: 0.9605, Prec: 0.9272, Rec: 0.8723, F1: 0.8989\n",
        "Epoch 69/75, Loss: 0.1017, Acc: 0.9617, Prec: 0.9422, Rec: 0.8629, F1: 0.9008\n",
        "Epoch 70/75, Loss: 0.0942, Acc: 0.9668, Prec: 0.9437, Rec: 0.8879, F1: 0.9149\n",
        "Epoch 71/75, Loss: 0.0855, Acc: 0.9699, Prec: 0.9596, Rec: 0.8879, F1: 0.9223\n",
        "Epoch 72/75, Loss: 0.0835, Acc: 0.9711, Prec: 0.9568, Rec: 0.8972, F1: 0.9260\n",
        "Epoch 73/75, Loss: 0.0921, Acc: 0.9649, Prec: 0.9316, Rec: 0.8910, F1: 0.9108\n",
        "Epoch 74/75, Loss: 0.0981, Acc: 0.9686, Prec: 0.9593, Rec: 0.8816, F1: 0.9188\n",
        "Epoch 75/75, Loss: 0.0986, Acc: 0.9617, Prec: 0.9392, Rec: 0.8660, F1: 0.9011\n",
        "\n",
        "Test Metrics -> Acc: 0.9811, Prec: 0.9640, Rec: 0.9469, F1: 0.9554\n",
        "\n",
        "batch_size = 64\n",
        "input_dim = X_train_tensor.shape[1]\n",
        "hidden_dims = [128, 64, 32]\n",
        "dropout = 0.2\n",
        "lr = 0.001\n",
        "epochs = 75\n",
        "\n",
        "8 saniye\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "KP1kBzyzy33-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Epoch 1/75, Loss: 0.4933, Acc: 0.8689, Prec: 0.8684, Rec: 0.4112, F1: 0.5581\n",
        "Epoch 2/75, Loss: 0.3614, Acc: 0.8965, Prec: 0.8861, Rec: 0.5576, F1: 0.6845\n",
        "Epoch 3/75, Loss: 0.2887, Acc: 0.9216, Prec: 0.9336, Rec: 0.6573, F1: 0.7715\n",
        "Epoch 4/75, Loss: 0.2466, Acc: 0.9335, Prec: 0.8826, Rec: 0.7726, F1: 0.8239\n",
        "Epoch 5/75, Loss: 0.2225, Acc: 0.9272, Prec: 0.8622, Rec: 0.7601, F1: 0.8079\n",
        "Epoch 6/75, Loss: 0.1944, Acc: 0.9442, Prec: 0.9056, Rec: 0.8069, F1: 0.8534\n",
        "Epoch 7/75, Loss: 0.1828, Acc: 0.9398, Prec: 0.9032, Rec: 0.7850, F1: 0.8400\n",
        "Epoch 8/75, Loss: 0.1700, Acc: 0.9460, Prec: 0.9038, Rec: 0.8193, F1: 0.8595\n",
        "Epoch 9/75, Loss: 0.1664, Acc: 0.9442, Prec: 0.9113, Rec: 0.8006, F1: 0.8524\n",
        "Epoch 10/75, Loss: 0.1553, Acc: 0.9467, Prec: 0.8960, Rec: 0.8318, F1: 0.8627\n",
        "Epoch 11/75, Loss: 0.1559, Acc: 0.9460, Prec: 0.9181, Rec: 0.8037, F1: 0.8571\n",
        "Epoch 12/75, Loss: 0.1411, Acc: 0.9523, Prec: 0.9125, Rec: 0.8442, F1: 0.8770\n",
        "Epoch 13/75, Loss: 0.1289, Acc: 0.9548, Prec: 0.9136, Rec: 0.8567, F1: 0.8842\n",
        "Epoch 14/75, Loss: 0.1356, Acc: 0.9536, Prec: 0.9103, Rec: 0.8536, F1: 0.8810\n",
        "Epoch 15/75, Loss: 0.1327, Acc: 0.9542, Prec: 0.9247, Rec: 0.8411, F1: 0.8809\n",
        "Epoch 16/75, Loss: 0.1346, Acc: 0.9511, Prec: 0.9324, Rec: 0.8162, F1: 0.8704\n",
        "Epoch 17/75, Loss: 0.1387, Acc: 0.9511, Prec: 0.9037, Rec: 0.8474, F1: 0.8746\n",
        "Epoch 18/75, Loss: 0.1368, Acc: 0.9542, Prec: 0.9276, Rec: 0.8380, F1: 0.8805\n",
        "Epoch 19/75, Loss: 0.1333, Acc: 0.9555, Prec: 0.9340, Rec: 0.8380, F1: 0.8834\n",
        "Epoch 20/75, Loss: 0.1240, Acc: 0.9548, Prec: 0.9308, Rec: 0.8380, F1: 0.8820\n",
        "Epoch 21/75, Loss: 0.1270, Acc: 0.9523, Prec: 0.8964, Rec: 0.8629, F1: 0.8794\n",
        "Epoch 22/75, Loss: 0.1153, Acc: 0.9605, Prec: 0.9448, Rec: 0.8536, F1: 0.8969\n",
        "Epoch 23/75, Loss: 0.1177, Acc: 0.9586, Prec: 0.9264, Rec: 0.8629, F1: 0.8935\n",
        "Epoch 24/75, Loss: 0.1209, Acc: 0.9555, Prec: 0.9252, Rec: 0.8474, F1: 0.8846\n",
        "Epoch 25/75, Loss: 0.1157, Acc: 0.9624, Prec: 0.9547, Rec: 0.8536, F1: 0.9013\n",
        "Epoch 26/75, Loss: 0.1169, Acc: 0.9555, Prec: 0.9371, Rec: 0.8349, F1: 0.8830\n",
        "Epoch 27/75, Loss: 0.1029, Acc: 0.9617, Prec: 0.9362, Rec: 0.8692, F1: 0.9015\n",
        "Epoch 28/75, Loss: 0.1066, Acc: 0.9573, Prec: 0.9288, Rec: 0.8536, F1: 0.8896\n",
        "Epoch 29/75, Loss: 0.1126, Acc: 0.9611, Prec: 0.9609, Rec: 0.8411, F1: 0.8970\n",
        "Epoch 30/75, Loss: 0.1129, Acc: 0.9548, Prec: 0.9082, Rec: 0.8629, F1: 0.8850\n",
        "Epoch 31/75, Loss: 0.1078, Acc: 0.9630, Prec: 0.9517, Rec: 0.8598, F1: 0.9034\n",
        "Epoch 32/75, Loss: 0.1033, Acc: 0.9586, Prec: 0.9412, Rec: 0.8474, F1: 0.8918\n",
        "Epoch 33/75, Loss: 0.1040, Acc: 0.9655, Prec: 0.9493, Rec: 0.8754, F1: 0.9109\n",
        "Epoch 34/75, Loss: 0.1101, Acc: 0.9674, Prec: 0.9590, Rec: 0.8754, F1: 0.9153\n",
        "Epoch 35/75, Loss: 0.1012, Acc: 0.9592, Prec: 0.9354, Rec: 0.8567, F1: 0.8943\n",
        "Epoch 36/75, Loss: 0.1047, Acc: 0.9624, Prec: 0.9336, Rec: 0.8754, F1: 0.9035\n",
        "Epoch 37/75, Loss: 0.1042, Acc: 0.9611, Prec: 0.9481, Rec: 0.8536, F1: 0.8984\n",
        "Epoch 38/75, Loss: 0.0946, Acc: 0.9636, Prec: 0.9398, Rec: 0.8754, F1: 0.9065\n",
        "Epoch 39/75, Loss: 0.0999, Acc: 0.9617, Prec: 0.9577, Rec: 0.8474, F1: 0.8992\n",
        "Epoch 40/75, Loss: 0.0995, Acc: 0.9598, Prec: 0.9241, Rec: 0.8723, F1: 0.8974\n",
        "Epoch 41/75, Loss: 0.1038, Acc: 0.9592, Prec: 0.9507, Rec: 0.8411, F1: 0.8926\n",
        "Epoch 42/75, Loss: 0.1072, Acc: 0.9642, Prec: 0.9430, Rec: 0.8754, F1: 0.9079\n",
        "Epoch 43/75, Loss: 0.0910, Acc: 0.9668, Prec: 0.9527, Rec: 0.8785, F1: 0.9141\n",
        "Epoch 44/75, Loss: 0.0969, Acc: 0.9636, Prec: 0.9340, Rec: 0.8816, F1: 0.9071\n",
        "Epoch 45/75, Loss: 0.0951, Acc: 0.9636, Prec: 0.9488, Rec: 0.8660, F1: 0.9055\n",
        "Epoch 46/75, Loss: 0.0973, Acc: 0.9655, Prec: 0.9404, Rec: 0.8847, F1: 0.9117\n",
        "Epoch 47/75, Loss: 0.1033, Acc: 0.9611, Prec: 0.9360, Rec: 0.8660, F1: 0.8997\n",
        "Epoch 48/75, Loss: 0.0989, Acc: 0.9642, Prec: 0.9583, Rec: 0.8598, F1: 0.9064\n",
        "Epoch 49/75, Loss: 0.0903, Acc: 0.9649, Prec: 0.9373, Rec: 0.8847, F1: 0.9103\n",
        "Epoch 50/75, Loss: 0.0836, Acc: 0.9705, Prec: 0.9757, Rec: 0.8754, F1: 0.9228\n",
        "Epoch 51/75, Loss: 0.0805, Acc: 0.9755, Prec: 0.9519, Rec: 0.9252, F1: 0.9384\n",
        "Epoch 52/75, Loss: 0.0978, Acc: 0.9661, Prec: 0.9652, Rec: 0.8629, F1: 0.9112\n",
        "Epoch 53/75, Loss: 0.0912, Acc: 0.9693, Prec: 0.9387, Rec: 0.9065, F1: 0.9223\n",
        "Epoch 54/75, Loss: 0.0929, Acc: 0.9636, Prec: 0.9488, Rec: 0.8660, F1: 0.9055\n",
        "Epoch 55/75, Loss: 0.0998, Acc: 0.9624, Prec: 0.9307, Rec: 0.8785, F1: 0.9038\n",
        "Epoch 56/75, Loss: 0.0868, Acc: 0.9655, Prec: 0.9375, Rec: 0.8879, F1: 0.9120\n",
        "Epoch 57/75, Loss: 0.0952, Acc: 0.9630, Prec: 0.9396, Rec: 0.8723, F1: 0.9047\n",
        "Epoch 58/75, Loss: 0.0843, Acc: 0.9711, Prec: 0.9568, Rec: 0.8972, F1: 0.9260\n",
        "Epoch 59/75, Loss: 0.0993, Acc: 0.9611, Prec: 0.9302, Rec: 0.8723, F1: 0.9003\n",
        "Epoch 60/75, Loss: 0.0900, Acc: 0.9711, Prec: 0.9568, Rec: 0.8972, F1: 0.9260\n",
        "Epoch 61/75, Loss: 0.0834, Acc: 0.9636, Prec: 0.9228, Rec: 0.8941, F1: 0.9082\n",
        "Epoch 62/75, Loss: 0.0747, Acc: 0.9724, Prec: 0.9601, Rec: 0.9003, F1: 0.9293\n",
        "Epoch 63/75, Loss: 0.0875, Acc: 0.9649, Prec: 0.9585, Rec: 0.8629, F1: 0.9082\n",
        "Epoch 64/75, Loss: 0.0921, Acc: 0.9655, Prec: 0.9236, Rec: 0.9034, F1: 0.9134\n",
        "Epoch 65/75, Loss: 0.0863, Acc: 0.9686, Prec: 0.9656, Rec: 0.8754, F1: 0.9183\n",
        "Epoch 66/75, Loss: 0.0908, Acc: 0.9699, Prec: 0.9505, Rec: 0.8972, F1: 0.9231\n",
        "Epoch 67/75, Loss: 0.0830, Acc: 0.9674, Prec: 0.9381, Rec: 0.8972, F1: 0.9172\n",
        "Epoch 68/75, Loss: 0.0739, Acc: 0.9730, Prec: 0.9455, Rec: 0.9190, F1: 0.9321\n",
        "Epoch 69/75, Loss: 0.0899, Acc: 0.9642, Prec: 0.9286, Rec: 0.8910, F1: 0.9094\n",
        "Epoch 70/75, Loss: 0.0866, Acc: 0.9686, Prec: 0.9625, Rec: 0.8785, F1: 0.9186\n",
        "Epoch 71/75, Loss: 0.0995, Acc: 0.9642, Prec: 0.9430, Rec: 0.8754, F1: 0.9079\n",
        "Epoch 72/75, Loss: 0.0804, Acc: 0.9705, Prec: 0.9477, Rec: 0.9034, F1: 0.9250\n",
        "Epoch 73/75, Loss: 0.0954, Acc: 0.9636, Prec: 0.9458, Rec: 0.8692, F1: 0.9058\n",
        "Epoch 74/75, Loss: 0.0888, Acc: 0.9668, Prec: 0.9351, Rec: 0.8972, F1: 0.9157\n",
        "Epoch 75/75, Loss: 0.0778, Acc: 0.9711, Prec: 0.9450, Rec: 0.9097, F1: 0.9270\n",
        "\n",
        "Test Metrics -> Acc: 0.9792, Prec: 0.9554, Rec: 0.9469, F1: 0.9511\n",
        "\n",
        "\n",
        "batch_size=64\n",
        "input_dim = X_train_tensor.shape[1]\n",
        "hidden_dims = [256,128, 64, 32]\n",
        "dropout = 0.2\n",
        "lr = 0.001\n",
        "epochs = 75\n",
        "\n",
        "10 saniye\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NaVMFbR6zW3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Epoch 1/75, Loss: 0.5538, Acc: 0.8350, Prec: 0.5954, Rec: 0.5639, F1: 0.5792\n",
        "Epoch 2/75, Loss: 0.4377, Acc: 0.9009, Prec: 0.9137, Rec: 0.5607, F1: 0.6950\n",
        "Epoch 3/75, Loss: 0.3529, Acc: 0.9260, Prec: 0.8889, Rec: 0.7227, F1: 0.7973\n",
        "Epoch 4/75, Loss: 0.3016, Acc: 0.9279, Prec: 0.8732, Rec: 0.7508, F1: 0.8074\n",
        "Epoch 5/75, Loss: 0.2627, Acc: 0.9360, Prec: 0.8982, Rec: 0.7695, F1: 0.8289\n",
        "Epoch 6/75, Loss: 0.2209, Acc: 0.9479, Prec: 0.9020, Rec: 0.8318, F1: 0.8655\n",
        "Epoch 7/75, Loss: 0.2072, Acc: 0.9404, Prec: 0.9036, Rec: 0.7882, F1: 0.8419\n",
        "Epoch 8/75, Loss: 0.1933, Acc: 0.9442, Prec: 0.9000, Rec: 0.8131, F1: 0.8543\n",
        "Epoch 9/75, Loss: 0.1711, Acc: 0.9498, Prec: 0.9085, Rec: 0.8349, F1: 0.8701\n",
        "Epoch 10/75, Loss: 0.1726, Acc: 0.9467, Prec: 0.9214, Rec: 0.8037, F1: 0.8586\n",
        "Epoch 11/75, Loss: 0.1651, Acc: 0.9504, Prec: 0.9116, Rec: 0.8349, F1: 0.8715\n",
        "Epoch 12/75, Loss: 0.1657, Acc: 0.9454, Prec: 0.9091, Rec: 0.8100, F1: 0.8567\n",
        "Epoch 13/75, Loss: 0.1432, Acc: 0.9536, Prec: 0.9303, Rec: 0.8318, F1: 0.8783\n",
        "Epoch 14/75, Loss: 0.1443, Acc: 0.9504, Prec: 0.9116, Rec: 0.8349, F1: 0.8715\n",
        "Epoch 15/75, Loss: 0.1358, Acc: 0.9548, Prec: 0.9278, Rec: 0.8411, F1: 0.8824\n",
        "Epoch 16/75, Loss: 0.1358, Acc: 0.9573, Prec: 0.9439, Rec: 0.8380, F1: 0.8878\n",
        "Epoch 17/75, Loss: 0.1310, Acc: 0.9580, Prec: 0.9410, Rec: 0.8442, F1: 0.8900\n",
        "Epoch 18/75, Loss: 0.1451, Acc: 0.9542, Prec: 0.9161, Rec: 0.8505, F1: 0.8821\n",
        "Epoch 19/75, Loss: 0.1327, Acc: 0.9555, Prec: 0.9433, Rec: 0.8287, F1: 0.8823\n",
        "Epoch 20/75, Loss: 0.1236, Acc: 0.9586, Prec: 0.9322, Rec: 0.8567, F1: 0.8929\n",
        "Epoch 21/75, Loss: 0.1345, Acc: 0.9580, Prec: 0.9349, Rec: 0.8505, F1: 0.8907\n",
        "Epoch 22/75, Loss: 0.1257, Acc: 0.9617, Prec: 0.9577, Rec: 0.8474, F1: 0.8992\n",
        "Epoch 23/75, Loss: 0.1236, Acc: 0.9605, Prec: 0.9300, Rec: 0.8692, F1: 0.8986\n",
        "Epoch 24/75, Loss: 0.1276, Acc: 0.9592, Prec: 0.9444, Rec: 0.8474, F1: 0.8933\n",
        "Epoch 25/75, Loss: 0.1291, Acc: 0.9517, Prec: 0.9326, Rec: 0.8193, F1: 0.8723\n",
        "Epoch 26/75, Loss: 0.1187, Acc: 0.9605, Prec: 0.9300, Rec: 0.8692, F1: 0.8986\n",
        "Epoch 27/75, Loss: 0.1178, Acc: 0.9611, Prec: 0.9609, Rec: 0.8411, F1: 0.8970\n",
        "Epoch 28/75, Loss: 0.1148, Acc: 0.9630, Prec: 0.9456, Rec: 0.8660, F1: 0.9041\n",
        "Epoch 29/75, Loss: 0.1037, Acc: 0.9642, Prec: 0.9521, Rec: 0.8660, F1: 0.9070\n",
        "Epoch 30/75, Loss: 0.1043, Acc: 0.9686, Prec: 0.9656, Rec: 0.8754, F1: 0.9183\n",
        "Epoch 31/75, Loss: 0.1091, Acc: 0.9630, Prec: 0.9367, Rec: 0.8754, F1: 0.9050\n",
        "Epoch 32/75, Loss: 0.1004, Acc: 0.9655, Prec: 0.9650, Rec: 0.8598, F1: 0.9094\n",
        "Epoch 33/75, Loss: 0.1013, Acc: 0.9636, Prec: 0.9398, Rec: 0.8754, F1: 0.9065\n",
        "Epoch 34/75, Loss: 0.0972, Acc: 0.9642, Prec: 0.9490, Rec: 0.8692, F1: 0.9073\n",
        "Epoch 35/75, Loss: 0.1095, Acc: 0.9586, Prec: 0.9474, Rec: 0.8411, F1: 0.8911\n",
        "Epoch 36/75, Loss: 0.1105, Acc: 0.9624, Prec: 0.9516, Rec: 0.8567, F1: 0.9016\n",
        "Epoch 37/75, Loss: 0.0990, Acc: 0.9617, Prec: 0.9676, Rec: 0.8380, F1: 0.8982\n",
        "Epoch 38/75, Loss: 0.0948, Acc: 0.9668, Prec: 0.9527, Rec: 0.8785, F1: 0.9141\n",
        "Epoch 39/75, Loss: 0.0988, Acc: 0.9592, Prec: 0.9384, Rec: 0.8536, F1: 0.8940\n",
        "Epoch 40/75, Loss: 0.0962, Acc: 0.9630, Prec: 0.9580, Rec: 0.8536, F1: 0.9028\n",
        "Epoch 41/75, Loss: 0.0961, Acc: 0.9661, Prec: 0.9588, Rec: 0.8692, F1: 0.9118\n",
        "Epoch 42/75, Loss: 0.1100, Acc: 0.9598, Prec: 0.9416, Rec: 0.8536, F1: 0.8954\n",
        "Epoch 43/75, Loss: 0.0974, Acc: 0.9693, Prec: 0.9595, Rec: 0.8847, F1: 0.9206\n",
        "Epoch 44/75, Loss: 0.0940, Acc: 0.9642, Prec: 0.9521, Rec: 0.8660, F1: 0.9070\n",
        "Epoch 45/75, Loss: 0.1116, Acc: 0.9580, Prec: 0.9262, Rec: 0.8598, F1: 0.8918\n",
        "Epoch 46/75, Loss: 0.1077, Acc: 0.9598, Prec: 0.9606, Rec: 0.8349, F1: 0.8933\n",
        "Epoch 47/75, Loss: 0.1027, Acc: 0.9655, Prec: 0.9618, Rec: 0.8629, F1: 0.9097\n",
        "Epoch 48/75, Loss: 0.0942, Acc: 0.9655, Prec: 0.9375, Rec: 0.8879, F1: 0.9120\n",
        "Epoch 49/75, Loss: 0.1029, Acc: 0.9611, Prec: 0.9420, Rec: 0.8598, F1: 0.8990\n",
        "Epoch 50/75, Loss: 0.1059, Acc: 0.9586, Prec: 0.9322, Rec: 0.8567, F1: 0.8929\n",
        "Epoch 51/75, Loss: 0.0974, Acc: 0.9624, Prec: 0.9516, Rec: 0.8567, F1: 0.9016\n",
        "Epoch 52/75, Loss: 0.1039, Acc: 0.9636, Prec: 0.9550, Rec: 0.8598, F1: 0.9049\n",
        "Epoch 53/75, Loss: 0.0874, Acc: 0.9649, Prec: 0.9344, Rec: 0.8879, F1: 0.9105\n",
        "Epoch 54/75, Loss: 0.0970, Acc: 0.9636, Prec: 0.9582, Rec: 0.8567, F1: 0.9046\n",
        "Epoch 55/75, Loss: 0.0909, Acc: 0.9624, Prec: 0.9336, Rec: 0.8754, F1: 0.9035\n",
        "Epoch 56/75, Loss: 0.0934, Acc: 0.9674, Prec: 0.9686, Rec: 0.8660, F1: 0.9145\n",
        "Epoch 57/75, Loss: 0.0959, Acc: 0.9674, Prec: 0.9498, Rec: 0.8847, F1: 0.9161\n",
        "Epoch 58/75, Loss: 0.0950, Acc: 0.9655, Prec: 0.9463, Rec: 0.8785, F1: 0.9111\n",
        "Epoch 59/75, Loss: 0.0923, Acc: 0.9693, Prec: 0.9658, Rec: 0.8785, F1: 0.9201\n",
        "Epoch 60/75, Loss: 0.1004, Acc: 0.9642, Prec: 0.9371, Rec: 0.8816, F1: 0.9085\n",
        "Epoch 61/75, Loss: 0.0933, Acc: 0.9636, Prec: 0.9747, Rec: 0.8411, F1: 0.9030\n",
        "Epoch 62/75, Loss: 0.0892, Acc: 0.9686, Prec: 0.9593, Rec: 0.8816, F1: 0.9188\n",
        "Epoch 63/75, Loss: 0.0840, Acc: 0.9699, Prec: 0.9723, Rec: 0.8754, F1: 0.9213\n",
        "Epoch 64/75, Loss: 0.0811, Acc: 0.9718, Prec: 0.9694, Rec: 0.8879, F1: 0.9268\n",
        "Epoch 65/75, Loss: 0.0866, Acc: 0.9674, Prec: 0.9498, Rec: 0.8847, F1: 0.9161\n",
        "Epoch 66/75, Loss: 0.0806, Acc: 0.9674, Prec: 0.9559, Rec: 0.8785, F1: 0.9156\n",
        "Epoch 67/75, Loss: 0.0821, Acc: 0.9718, Prec: 0.9631, Rec: 0.8941, F1: 0.9273\n",
        "Epoch 68/75, Loss: 0.0789, Acc: 0.9674, Prec: 0.9410, Rec: 0.8941, F1: 0.9169\n",
        "Epoch 69/75, Loss: 0.0843, Acc: 0.9693, Prec: 0.9444, Rec: 0.9003, F1: 0.9219\n",
        "Epoch 70/75, Loss: 0.0877, Acc: 0.9674, Prec: 0.9529, Rec: 0.8816, F1: 0.9159\n",
        "Epoch 71/75, Loss: 0.0854, Acc: 0.9674, Prec: 0.9753, Rec: 0.8598, F1: 0.9139\n",
        "Epoch 72/75, Loss: 0.0766, Acc: 0.9693, Prec: 0.9533, Rec: 0.8910, F1: 0.9211\n",
        "Epoch 73/75, Loss: 0.0833, Acc: 0.9718, Prec: 0.9726, Rec: 0.8847, F1: 0.9266\n",
        "Epoch 74/75, Loss: 0.0855, Acc: 0.9674, Prec: 0.9410, Rec: 0.8941, F1: 0.9169\n",
        "Epoch 75/75, Loss: 0.0849, Acc: 0.9668, Prec: 0.9467, Rec: 0.8847, F1: 0.9147\n",
        "\n",
        "Test Metrics -> Acc: 0.9830, Prec: 0.9727, Rec: 0.9469, F1: 0.9596\n",
        "\n",
        "batch_size= 64\n",
        "input_dim = X_train_tensor.shape[1]\n",
        "hidden_dims = [512,256,128, 64, 32]\n",
        "dropout = 0.2\n",
        "lr = 0.001\n",
        "epochs = 75\n",
        "\n",
        "13 saniye\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7g4t1TrBzW5t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}